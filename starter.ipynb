{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Review Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generate a Model to Classify Sentiment of a Review Text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KCWwIIzk_W-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You're a movie director, and you just released a film you poured your soul (and money) into making. You are curious as to what people thought of your movie. Reviews are pouring in every day, hundreds upon hundreds. You want to read through them all, but you physically can't.\n",
        "\n",
        "On top of being a director, you are also a machine learning programmer, and you think it would be cool to make a model that can look at the text of any review and classify whether it is positive or negative, just by looking at the words. \n",
        "\n",
        "You find a giant dataset of IMDB reviews for a variety of movies, tagged for having `positive` (1) or `negative` (0) sentiments, depending on the rating. \n",
        "\n",
        "With this IMDB dataset, you decided to build and train an AI `Sentiment Analysis` model that can classify any review as positive or negative. That way, you can run the model on any review or comment that comes in for your movie and quickly tell if it is positive or negative without reading it yourself. \n",
        "\n",
        "(Note: This model is called a `Naive-Bayes Classifier`. This model can actually compute the sentiment for **any** text -- reviews, tweets, comments, etc!)\n",
        "\n",
        "(Another note: This is a difficult task! Do not be discouraged if you struggle, and don't be scared to ask for help.)"
      ],
      "metadata": {
        "id": "ZLV_Dtl2_ks7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries (Do not edit) \n",
        "\n",
        "Load python packages necessary for building the sentiment analysis model download the IMDB dataset. Do not edit this cell. "
      ],
      "metadata": {
        "id": "Xzn9mL_b8RfA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp8stAtk8I1D",
        "outputId": "35322f1c-ae30-4cc3-8995-dae234fe12b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IViQp6-J-uZYOsZY4nw_XLE3y9QXhyIw\n",
            "To: /content/testing_aides.py\n",
            "100% 1.31k/1.31k [00:00<00:00, 1.83MB/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive # file\n",
        "import string # tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt # confusion matrix\n",
        "import math\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split # model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# for testing later\n",
        "! gdown --id 1IViQp6-J-uZYOsZY4nw_XLE3y9QXhyIw\n",
        "import testing_aides as tester\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What does your data look like? (Do Not Edit)"
      ],
      "metadata": {
        "id": "En0wrljAh3Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data!\n",
        "! gdown --id 1vexo0MMtjPzSv5CONn5t8QH3IKvewedk\n",
        "reviewData = pd.read_csv(\"/content/labeledTrainData.tsv\", delimiter=\"\\t\")\n",
        "reviewData.head() # what does this file look like?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "yOnDiqRQh7et",
        "outputId": "e239d251-842b-48a4-c33f-3a3a6abc0f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vexo0MMtjPzSv5CONn5t8QH3IKvewedk\n",
            "To: /content/labeledTrainData.tsv\n",
            "100% 33.6M/33.6M [00:00<00:00, 35.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  sentiment                                             review\n",
              "0  5814_8          1  With all this stuff going down at the moment w...\n",
              "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
              "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
              "3  3630_4          0  It must be assumed that those who praised this...\n",
              "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75fe638b-ec75-4f34-a199-03e60d709304\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5814_8</td>\n",
              "      <td>1</td>\n",
              "      <td>With all this stuff going down at the moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2381_9</td>\n",
              "      <td>1</td>\n",
              "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7759_3</td>\n",
              "      <td>0</td>\n",
              "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3630_4</td>\n",
              "      <td>0</td>\n",
              "      <td>It must be assumed that those who praised this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9495_8</td>\n",
              "      <td>1</td>\n",
              "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75fe638b-ec75-4f34-a199-03e60d709304')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75fe638b-ec75-4f34-a199-03e60d709304 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75fe638b-ec75-4f34-a199-03e60d709304');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In lecture, you learned how to compute the sentiment of a text using `multinomial Naive-Bayes`. Recall you need two different kinds of probability - `prior` and `posterior`. \n",
        "\n",
        "So, there are three parts to writing this code:\n",
        "\n",
        "1.   Calculating **prior probabilities** using the given reviews (the \"train data\") **(Part 1)**\n",
        "2.   Creating methods to calculate **posterior probabilities** of individual words in a review **(Part 2)**\n",
        "3.   Classifying each review in the \"test data\" as positive or negative based on the combined prior and posterior probabilities **(Part 3)**\n",
        "\n",
        "The goal is to write code that classifies each review in a **list of reviews** (`reviews_test`) as negative (0) or positive (1) based on probabilities. The final result should be a **list of sentiments** (`classified_sentiments`), which has one sentiment value for each test review.\n",
        "- Ex. [0, 1, 1, 0, 1...] \n"
      ],
      "metadata": {
        "id": "uQhbxceMD49P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables to Know\n",
        "These are provided variables that you will have to use to develop your code! Know them well.\n",
        "*   `sentimentClasses` is a list of the sentiments, `0` (which represents negative) and `1` (which represents positive).\n",
        "  * `sentimentClasses = [0,1]`\n",
        "  * We will later *classify* each test review into the positive or negative class.\n",
        "  \n",
        "*   `reviews` is a list of all the **review texts**. \n",
        "  * This is the *review* column of your data table.\n",
        "  * Ex. `[\"This was a great movie\", \"Wow! What a flop!\", ...]`\n",
        "*   `sentiment` is a list of the **sentiments** (0 or 1), corresponding to each review from `reviews`. This is the *sentiment* column of the data file.\n",
        "  *  This is the *sentiment* column of your data table\n",
        "  * Ex. `[1, 0, 0, 1, ...]`\n",
        "\n",
        "`reviews[0]` corresponds to `sentiments[0]`, and so on.\n",
        "* Ex. `\"This was a great movie\"` corresponds to `1` (positive)\n",
        "\n",
        "**Note:** The cell below defines these variables for you. You do not need to define them yourself.\n"
      ],
      "metadata": {
        "id": "Sgv-kHhxYk0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provided variables (DO NOT EDIT!)\n",
        "\n",
        "# reviews is the list of reviews\n",
        "reviews = reviewData['review'].values   # from 'review' column\n",
        "# sentiments is the list of corresponding sentiments\n",
        "sentiments = reviewData['sentiment'].values   # from 'sentiment' column\n",
        "\n",
        "# split reviews and sentiments for training and testing\n",
        "reviews_train, reviews_test, sentiments_train, sentiments_test = train_test_split(reviews, sentiments, test_size=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "# store the two unique sentiments, 0 (negative) and 1 (positive) in a sentimentClasses\n",
        "sentimentClasses = np.unique(sentiments) # [0, 1]"
      ],
      "metadata": {
        "id": "yyFzSY6m-jP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Part 1: Calculate Prior Probabilities\n"
      ],
      "metadata": {
        "id": "eJB3k_hF_kpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Group Reviews by Sentiment Class\n",
        "First, it's useful to group all the reviews in the training dataset by sentiment. \n",
        "\n",
        "Say you do this by creating one list of all the positive reviews, and one list of all the negative reviews. We can store these lists in a **dictionary**. \n",
        "\n",
        "We will use dictionaries in this lab to organize our data into our two sentiment classes, 0 and 1.\n",
        "\n",
        "This is what the dictionary `ReviewsByClass` should look like:\n",
        "- Keys: the sentiment classes, 0 and 1\n",
        "- Values: lists of all the negative reviews, and all the positive reviews (respectively)"
      ],
      "metadata": {
        "id": "tdqp5z6jSzJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Example*: Hypothetically, say your reviews list was: \n",
        "  > `[\"Good acting.\", \"I love this film!\", \"Truly horrible. What a flop.\"]`\n",
        "\n",
        "...and your sentiments list was:\n",
        "  > `[1, 1, 0]`\n",
        "\n",
        "`ReviewsByClass` should look something like:\n",
        "  > `{0: [\"Truly horrible. What a flop.\"], 1: [\"Good acting.\", \"I love this film!\"]}`\n",
        "\n",
        "  - Dictionaries have the format `{key: value, key: value, ...}`"
      ],
      "metadata": {
        "id": "3FF4OQKOYLw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: fill in ReviewsByClass\n",
        "# ReviewsByClass should have two keys, 0 and 1 (one for each sentiment class).\n",
        "# the value for 0 should be a list of all the negative reviews\n",
        "# the value for 1 should be a list of all the positive reviews\n",
        "\n",
        "# first step: go through all the reviews. for each review, sort them into either\n",
        "# negative or positive list based on what its corresponding sentiment is.\n",
        "\n",
        "ReviewsByClass = {} \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NkU8xyNhV0nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate the Prior Probabilities\n",
        "Complete a `dictionary` called `PriorProbabilityByClass`.\n",
        "- Keys: the sentiment classes, 0 and 1\n",
        "- Values: the prior probabilities\n",
        "  - prior probability: the probability that **any** review is in a particular sentiment class\n",
        "\n",
        "**Note:** **Prior probability of a class = log((# of items in that class) / (total # of items))**"
      ],
      "metadata": {
        "id": "Ni56G76pSV-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Example*: Hypothetically, say your reviews list was: \n",
        "  > `[\"Good acting.\", \"I love this film!\", \"Truly horrible. What a flop.\"]`\n",
        "\n",
        "...and your sentiments list was:\n",
        "  > `[1, 1, 0]`\n",
        "\n",
        "There is 1 negative review, and 2 positive reviews. In total, there are 3 reviews. \n",
        "\n",
        "Therefore, the negative prior probability is `1/3`, and the positive prior  probability is `2/3`.\n",
        "\n",
        "Your final dictionary, `PriorProbabilityByClass`, for this example dataset should look something like:\n",
        "  > `{0: 0.33, 1: 0.67}`\n"
      ],
      "metadata": {
        "id": "rOTAfIcZjJe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: fill in PriorProbabilityByClass\n",
        "# PriorProbabilityByClass also has two keys, one for each sentiment class.\n",
        "# the values for each key should be the prior probability for each corresponding class.\n",
        "# ^ a decimal value -> log(# of items in that class / total # of items)\n",
        "\n",
        "# Hint: can you use ReviewsByClass for this?\n",
        "\n",
        "PriorProbabilityByClass = {}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMukh4GuI3kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Create Methods to Calculate Posterior Probabilities\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fIGiFhrRI-2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To write the classification code, you will need some **helper methods and variables** to help calculate the posterior probabilities. Build them by following the steps below. Each step depends on the last! \n",
        "\n",
        "*Note*: Additional information for each of the steps is above their code cells.\n",
        "Testing cells are provided after each step so you can check your progress.\n",
        "\n",
        "1. Write a method to `tokenize` a review\n",
        "2. Create the dictionary `BagOfWordsByClass`, which holds a **Bag of Words** dictionary for each sentiment class\n",
        "3. Write a method `computePosteriorProbs(word, c, reviewsByClass, bagOfWords)`"
      ],
      "metadata": {
        "id": "OpqzaeuGTI3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Tokenize (preprocessing)\n",
        "Write a method to `tokenize` a review.*\n",
        "  - You should do **preprocessing** on the review (this means getting rid of anything from the text that won't be useful for the analysis). The steps below can be done in any order:\n",
        "    - Make the text lowercase\n",
        "    - Strip the text of any invalid characters (like `\\`)\n",
        "    - Split the review into a list of individual words\n",
        "     - You can do this by splitting by punctuation, spaces...\n",
        "\n",
        "    \n",
        "- **Return** a list of preprocessed words.\n",
        "\n",
        "**Hint**: the Python String [**lower(), strip(), replace(), split()** ](https://www.programiz.com/python-programming/methods/string) methods \n",
        "\n",
        "*Making this a method is useful later on, because you will need to tokenize a LOT of reviews.\n"
      ],
      "metadata": {
        "id": "WrH3mp7WsR29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Example*: \n",
        "\n",
        "`result = tokenize(\"Yikes! That movie stunk a \\lot\\.\")`\n",
        "\n",
        "`result` should be something like `[\"yikes\", \"that\", \"movie\", \"stunk\", \"a\", \"lot\"]`\n"
      ],
      "metadata": {
        "id": "NdzoO-PTbGl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input: a review\n",
        "# RETURN: a list of preprocessed words\n",
        "def tokenize(review):\n",
        "    # Preprocessing (any order):\n",
        "    # - make the text lowercase\n",
        "    # - strip the text of any unneccessary characters\n",
        "    # - split the text into a list of words\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "ETxVqKnyLj--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing cell (optional): tokenize a string of text using your method!\n",
        "# the output should be a list of plain words.\n",
        "# suggestions to tokenize:\n",
        "# - a review from the dataset: ex. reviews[0]\n",
        "# - your own made-up review\n",
        "# note: don't spend too long on this step; the following steps are more time-consuming.\n",
        "\n"
      ],
      "metadata": {
        "id": "h4QMwquWOeQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Create and store bag of words for each class\n",
        "Create the dictionary `BagOfWordsByClass`, which holds a **Bag of Words** dictionary **for each sentiment class**. \n",
        "\n",
        "\n",
        "Here, you will create **two** Bags of Words, one for 0 (negative class) and one for 1 (positive class) and store them both inside `BagOfWordsByClass`:\n",
        "- Keys: the two sentiment classes\n",
        "- Values: the two corresponding Bag of Words dictionaries\n",
        "\n"
      ],
      "metadata": {
        "id": "S4OVYHf0P3Ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag Of Words** is a dictionary with\n",
        "- Keys: **unique** words in the text\n",
        "- Values: the word **count**; how many of those words seen in the text.\n",
        "  - Here, the \"text\" is a list of reviews\n",
        "\n",
        "\n",
        "*Example*: Given the list `[\"happy birthday\", \"i am happy\", \"who am i\"]`\n",
        "- Bag of Words: `{\"happy\": 2, \"birthday\": 1, \"i\": 2, \"am\": 2, \"who\": 1}`\n",
        "\n"
      ],
      "metadata": {
        "id": "-VSXGJxEfgok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hint**: \n",
        "- For each class, go through the reviews, each review word by word (what method have we written to split reviews into words?). \n",
        "- For each word: if the word is already in your Bag Of Words dictionary for that class (as a key), increase the word count (the value of that key). \n",
        "- If the word is NOT in your dictionary already, you will have to **add it to the dictionary**.\n",
        "\n",
        "\n",
        "How do you check if a word is in your Bag Of Words?\n",
        "\n",
        "  - You can use the keyword `in` to check if a key exists in a dictionary:\n",
        "      - ex. `if \"funny\" in someArbitraryBagOfWords:`\n",
        "\n",
        "  - You can also use `set`s to store all the unique words you've seen so far in a class or overall. \n",
        "    - A `set` is basically a `list` of unique things that don't have an order. \n",
        "    - It's a lot quicker to check if something is in a `set` than if it is in a `list`. "
      ],
      "metadata": {
        "id": "IfrkjGdPgk59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `set` we have declared for you is called `vocab`, to keep track of all the unique words you see in the dataset, regardless of class. If you see a unique word, add to `vocab`.\n",
        "* `vocab` --> set of **all unique words**\n",
        "  * This is useful later on.\n"
      ],
      "metadata": {
        "id": "lw7l_yPDfm5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we provide a **testing aide** for this part, `testBagOfWordsByClass`, which you can use to check your final `BagOfWordsByClass` dictionary against the original dataset. \n",
        "- Don't worry if your dictionary isn't 100% accurate; your `tokenize()` method may just look different from the tester's. This is just a sanity check."
      ],
      "metadata": {
        "id": "pnOIKBKHfkYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create two bag of words dictionaries, one for neg class, one for pos class\n",
        "# for each review in neg class, split it into words\n",
        "# and for each word, if it is new to neg bag of words, add() to neg bag of words, \n",
        "# if not, add to the count in neg bag of words.\n",
        "# same for pos.\n",
        "# note: also fill vocab: add any new word to vocab\n",
        "# finally, store both in BagOfWordsByClass, by class.\n",
        "\n",
        "BagOfWordsByClass = {}\n",
        "vocab = set()   # set of all unique words. add to it as you go along\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hub7IQ7hLyu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing cell (optional): run this cell after completing BagOfWordsByClass.\n",
        "# to see how accurate your bag-of-words dictionary is.\n",
        "# this is working code - you don't have to write your own testing code here.\n",
        "# change the testWord and run the cell again!\n",
        "\n",
        "testWord = \"ladybug\"\n",
        "tester.testBagOfWordsByClass(testWord, reviews, sentiments, BagOfWordsByClass)\n",
        "\n",
        "# !! don't worry if the numbers aren't exactly the same !!\n",
        "\n",
        "# IMPORTANT: remember that your bag-of-words uses TOKENIZED words - words that\n",
        "# have gone through whatever preprocessing you wrote in tokenize().\n",
        "# as the words in the original dataset are unprocessed, this may result in inconsistencies.\n",
        "\n",
        "# the code uses its OWN VERSION of tokenize() that lowercases and gets rid of symbols.\n",
        "# so, there still may be inconsistencies in word counts."
      ],
      "metadata": {
        "id": "r2K1Bmi7VOAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Calculate posterior probabilities\n",
        "3. Write a method `computePosteriorProbs(word, c, reviewsByClass, bagOfWords)`\n",
        "  - This calculates **posterior probability**: the probability of a given **word** being in a given **class**.\n",
        "    - Parameters include:\n",
        "      - `word`, a string, e.g. \"great\"\n",
        "      - `c`, a given class, e.g. 1\n",
        "      - `reviewsByClass`, the dictionary `ReviewsByClass`\n",
        "      - `bagOfWordsByClass`, the dictionary `BagOfWordsByClass`\n",
        "  - `computePosteriorProbs` should return a number, the probability value.\n",
        "\n",
        "**Note: Posterior Probabilty given word and class = log( `# of that word in the class` + 1 / `# of words in the class` + `# of unique words in total`)**\n",
        "\n",
        "\n",
        "**Note 2:** Sometimes, a word will be in one class but not the other. (Ex. \"fantastic\" might have been seen in the positive class, but not the negative class). \n",
        "- So, you must check whether the inputted `word` is in the Bag of Words for the inputted `class`.\n",
        "  - If it isn't, you will have to **add that word to the bag of words for that class with the initial count `0`**."
      ],
      "metadata": {
        "id": "uSP1JFm4VANN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write a method to calculate posterior probability\n",
        "# given a word and a class; the probability that the word will be in the class.\n",
        "# RETURN the probability value\n",
        "def computePosteriorProbs(word, c, reviewsByClass, bagOfWordsByClass):\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "haMWYH8dL3gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing cell (optional): test computePosteriorProbs()\n",
        "# you can refer to the simple dataset from the lecture as an example of what the\n",
        "# posterior probability should look like.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OalsloHAVNm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Final classification\n",
        "\n",
        "Finally, using the methods and variables you have at your disposal, **write the final classification code** and fill `classified_sentiments`! \n",
        "\n",
        "### Task:\n",
        "For each review in a **list of reviews** (`reviews_test`), classify each review as negative (0) or positive (1) using probabilities. The final result should be a **list of sentiments** (`classified_sentiments`), which has one sentiment value for each test review.\n",
        "- Ex. [0, 1, 1, 0, 1...] \n",
        "\n",
        "\n",
        "### Process:\n",
        "You must classify each review as positive or negative. How do you do this?\n",
        "\n",
        "For each review, you will calculate a **probability score** for each sentiment class; a score for positive sentiment and score for negative sentiment. Then, in the end, you can choose the sentiment with the higher score to be the prediction for that review.\n",
        "\n",
        "Calculating a probability score for a class involves **cumulatively adding posterior probabilities to the prior probability**.\n",
        "\n",
        "- So, for each review, **for each sentiment class**, get the prior probability. - Then, for each word in the review, calculate the posterior probability and add it to the prior probability to get the final probability score.\n",
        "  - **Note**: if the word *hasn't been seen before in the training dataset* (i.e. it is not in the vocab), we don't have any useful information about it, so it's best to skip it entirely.\n",
        "\n",
        "\n",
        "Then, you should choose the sentiment class (0 or 1) with the higher final score for the review. \n",
        "- You can use the Python `max(..., key=...)` function for this.\n",
        "\n",
        "\n",
        "Finally, add that sentiment value to `classified_sentiments`. This is already initialized, so you just need to fill it. You should not write this process as a method."
      ],
      "metadata": {
        "id": "CHZZi238VO9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classified_sentiments = [] # the final list you should store your classified sentiments in\n",
        "\n",
        "# from a list of test reviews  (reviews_test)\n",
        "# for each review, calculate the probability scores for each sentiment class\n",
        "# and choose the sentiment whose score is higher.\n",
        "# calculate these scores by adding posterior probs (word by word) to the prior prob.\n",
        "# add the final classification to classified_sentiments\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vGWA---y-Jsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate your model (Do not edit)\n",
        "\n",
        "Now that you've built your classifier and created a final list of sentiments, run the following code cells to evaluate your model for accuracy and other metrics. The following code uses methods from a package called `sklearn`."
      ],
      "metadata": {
        "id": "vJVnscDToNJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy of your classification\n",
        "# (sentiments_test contains the correct sentiments)\n",
        "accuracy_score(sentiments_test, classified_sentiments)"
      ],
      "metadata": {
        "id": "J8RrHkNJM_Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate performance of the model on several metrics\n",
        "classification_report(sentiments_test, classified_sentiments)"
      ],
      "metadata": {
        "id": "xGd0y932Mu_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw the confusion matrix using matplotlib\n",
        "def drawConfusionMatrix():\n",
        "\n",
        "  # get the data for the confusion matrix\n",
        "  cnf_data = confusion_matrix(sentiments_test, classified_sentiments)\n",
        "\n",
        "  # set up the figure \n",
        "  figure = plt.figure()\n",
        "  axes = figure.add_subplot(111)\n",
        "  \n",
        "  # using the matshow() function\n",
        "  caxes = axes.matshow(cnf_data, cmap='Blues') # cmap -> colors\n",
        "\n",
        "  # title\n",
        "  plt.title('Confusion Matrix For Your Model')\n",
        "\n",
        "  # axis titles\n",
        "  axes.set_xlabel(\"Predicted sentiment\")\n",
        "  axes.set_ylabel(\"Actual sentiment\")\n",
        "\n",
        "  # axis ticks and labels\n",
        "  axes.tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
        "  axes.tick_params(axis=\"y\", left=True, labelleft=True, rotation=90)\n",
        "\n",
        "  labels = ['positive', 'negative']\n",
        "  axes.set_xticklabels(['']+labels)\n",
        "  axes.set_yticklabels(['']+labels)\n",
        "\n",
        "  # inner labels\n",
        "  for (i, j), z in np.ndenumerate(cnf_data):\n",
        "      axes.text(j, i, '{}'.format(z), ha='center', va='center', fontsize=15,\n",
        "                bbox=dict(boxstyle='round', facecolor='white'))\n",
        "\n",
        "  plt.grid(False) # get rid of extra gridlines\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Yvkn6uy16w3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drawConfusionMatrix()"
      ],
      "metadata": {
        "id": "CR6In4MaGzre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflection\n",
        "\n",
        "Try running your classification code on your own made-up reviews! Can you make up a review that the model fails on? (The review is positive but it returns negative, vice versa). \n",
        "\n",
        "You can also try running the method on single words to see what words are considered indicative of positive or negative sentiment.\n",
        "\n",
        "Can you think of any bigger datasets that this model would fail on?\n",
        "\n"
      ],
      "metadata": {
        "id": "9ocgFNBUaIyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Activity: Improving Your Model By Improving Preprocessing\n",
        "\n",
        "Look back at the `tokenizing` step of this lab (Part 2). Try running `tokenize` on `reviews[9]`. Notice anything weird?\n",
        "\n",
        "Your `tokenize` method includes **preprocessing** steps like lowercasing the text, getting rid of extraneous symbols, and splitting the review into words. This is all to reduce the raw review text into useful information -- important words.\n",
        "\n",
        "\n",
        "There are really numerous ways to do preprocessing. See if you can improve your `tokenize` method further by employing different methods. \n",
        "\n",
        "- One idea is to try removing words that aren't important for analyzing sentiment. \n",
        "  - For example, `\"I\"` and `\"or\"` aren't really positive or negative (or they shouldn't be!), so they shouldn't have much effect on the final computed sentiment of a review.\n",
        "\n",
        "- **Hint**: The `nltk` python package is specialized for text analysis and it may have some useful methods for this task.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gk0oAc6bbICS"
      }
    }
  ]
}